{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0260395e",
   "metadata": {},
   "source": [
    "# 金融异常检测任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65cbf8",
   "metadata": {},
   "source": [
    "## 1. 实验介绍\n",
    "\n",
    "反欺诈是金融行业永恒的主题，在互联网金融信贷业务中，数字金融反欺诈技术已经得到广泛应用并取得良好效果，这其中包括了近几年迅速发展并在各个领域\n",
    "得到越来越广泛应用的神经网络。本项目以互联网智能风控为背景，从用户相互关联和影响的视角，探索满足风控反欺诈领域需求的，可拓展、高效的神经\n",
    "网络应用方案，从而帮助更好地识别欺诈用户。\n",
    "\n",
    "本项目主要关于实现预测模型(**项目用图神经网络举例，具体实现可以使用其他模型**)，进行节点异常检测任务，并验证模型精度。而本项目基于的数据集[DGraph](https://dgraph.xinye.com/introduction)，[DGraph](https://dgraph.xinye.com/introduction)\n",
    "是大规模动态图数据集的集合，由真实金融场景中随着时间演变事件和标签构成。\n",
    "\n",
    "### 1.1 实验目的\n",
    "\n",
    "- 了解如何使用Pytorch进行神经网络训练\n",
    "- 了解如何使用Pytorch-geometric等图网络深度学习库进行简单图神经网络设计(推荐使用GAT, GraphSAGE模型)。\n",
    "- 了解如何利用MO平台进行模型性能评估。\n",
    "\n",
    "### 1.2 预备知识\n",
    "- 具备一定的深度学习理论知识，如卷积神经网络、损失函数、优化器，训练策略等。\n",
    "- 了解并熟悉Pytorch计算框架。\n",
    "- 学习Pytorch-geometric，请前往：https://pytorch-geometric.readthedocs.io/en/latest/\n",
    "    \n",
    "### 1.3实验环境\n",
    "- numpy = 1.26.4  \n",
    "- pytorch = 2.3.1  \n",
    "- torch_geometric = 2.5.3  \n",
    "- torch_scatter = 2.1.2  \n",
    "- torch_sparse = 0.6.18  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bcdfd7",
   "metadata": {},
   "source": [
    "## 2. 实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b2e6e",
   "metadata": {},
   "source": [
    "### 2.1 数据集信息\n",
    "DGraph-Fin 是一个由数百万个节点和边组成的有向无边权的动态图。它代表了Finvolution Group用户之间的社交网络，其中一个节点对应一个Finvolution 用户，从一个用户到另一个用户的边表示**该用户将另一个用户视为紧急联系人**。\n",
    "下面是`位于dataset/DGraphFin目录`的DGraphFin数据集的描述:\n",
    "```\n",
    "x:  20维节点特征向量\n",
    "y:  节点对应标签，一共包含四类。其中类1代表欺诈用户而类0代表正常用户(实验中需要进行预测的两类标签)，类2和类3则是背景用户，即无需预测其标签。\n",
    "edge_index:  图数据边集,每条边的形式(id_a,id_b)，其中ids是x中的索引\n",
    "edge_type: 共11种类型的边\n",
    "edge_timestamp: 脱敏后的时间戳\n",
    "train_mask, valid_mask, test_mask: 训练集，验证集和测试集掩码\n",
    "```\n",
    "本预测任务为识别欺诈用户的节点预测任务,只需要将欺诈用户（Class 1）从正常用户（Class 0）中区分出来。需要注意的是，其中测试集中样本对应的label**均被标记为-100**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19eff1",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 2.2 导入相关包\n",
    "\n",
    "导入相应模块，设置数据集路径、设备等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f5ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DGraphFin\n",
    "from utils.utils import prepare_folder\n",
    "from utils.evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "#设置gpu设备\n",
    "device = 0\n",
    "#device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "#device = torch.device(device)\n",
    "device = torch.device(\"cuda:0\")#设置device为CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae26d1e",
   "metadata": {},
   "source": [
    "### 2.3 数据处理\n",
    "\n",
    "在使用数据集训练网络前，首先需要对数据进行归一化等预处理，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6978c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##处理data\n",
    "path='./datasets/632d74d4e2843a53167ee9a1-momodel/' #数据保存路径\n",
    "save_dir='./results/' #模型保存路径\n",
    "dataset_name='DGraph'\n",
    "dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor()).to(device)   ##从momodel里面读入已有的数据，并将数据转为稀疏张量形式，存在device中，读到的数据为dataset\n",
    "\n",
    "nlabels = dataset.num_classes\n",
    "if dataset_name in ['DGraph']:\n",
    "    nlabels = 2    #本实验中仅需预测类0和类1\n",
    "\n",
    "data = dataset[0]   #data为data的第一个数据图\n",
    "data.adj_t = data.adj_t.to_symmetric() #将有向图转化为无向图\n",
    "\n",
    "if dataset_name in ['DGraph']:\n",
    "    x = data.x\n",
    "    x = (x - x.mean(0)) / x.std(0)\n",
    "    data.x = x\n",
    "if data.y.dim() == 2:\n",
    "    data.y = data.y.squeeze(1)\n",
    "\n",
    "split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}  #划分训练集，验证集\n",
    "\n",
    "train_idx = split_idx['train']                     #train_idx为训练集\n",
    "result_dir = prepare_folder(dataset_name,'SAGE')     #创建新目录保存模型（每次删除已经存在的，重新创建）\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff24b7a",
   "metadata": {},
   "source": [
    "这里我们可以查看数据各部分维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dbb92f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3700550, 20], edge_attr=[4300999], y=[3700550], train_mask=[857899], valid_mask=[183862], test_mask=[183840], adj_t=[3700550, 3700550, nnz=7994520])\n",
      "torch.Size([3700550, 20])\n",
      "torch.Size([3700550])\n",
      "20\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m#label\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(data.x.shape)  #feature\n",
    "print(data.y.shape)  #label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c547487",
   "metadata": {},
   "source": [
    "### 2.4 定义模型\n",
    "这里我们使用简单的多层感知机作为例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda207af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##graphsage模型\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(SAGE, self).__init__()   ##初始化\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index: Union[Tensor, SparseTensor]):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            if self.batchnorm: \n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x.log_softmax(dim=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fe53df",
   "metadata": {},
   "source": [
    "配置后续训练、验证、推理用到的参数。可以调整以下超参以提高模型训练后的验证精度：\n",
    "\n",
    "- `epochs`：在训练集上训练的代数；\n",
    "- `lr`：学习率；\n",
    "- `num_layers`：网络的层数；\n",
    "- `hidden_channels`：隐藏层维数；\n",
    "- `dropout`：dropout比例；\n",
    "- `weight_decay`：正则化项的系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0b63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##模型参数\n",
    "mlp_parameters = {\n",
    "    'lr': 0.01\n",
    "    , 'num_layers': 2\n",
    "    , 'hidden_channels': 128\n",
    "    , 'dropout': 0.0\n",
    "    , 'batchnorm': False\n",
    "    , 'weight_decay': 5e-7\n",
    "                  }\n",
    "epochs = 200\n",
    "log_steps =10 # log记录周期"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990877a",
   "metadata": {},
   "source": [
    "初始化模型，并使用**Area Under the Curve (AUC)** 作为模型评价指标来衡量模型的表现。AUC通过对ROC曲线下各部分的面积求和而得。\n",
    "\n",
    "具体计算过程参见 https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/metrics/_ranking.py#L363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734da961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MLP initialized\n"
     ]
    }
   ],
   "source": [
    "para_dict = mlp_parameters          ##para_dict为原始设置的模型参数\n",
    "model_para = mlp_parameters.copy()   ##备份model的参数\n",
    "model_para.pop('lr')\n",
    "model_para.pop('weight_decay')      ##得到的model_para为去掉lr和weight_dacay之后的参数集合\n",
    "model = SAGE(in_channels=data.x.size(-1), out_channels=nlabels, **model_para).to(device)  ##创建一个SAGE模型model，存入GPU\n",
    "print(f'Model SAGE initialized')\n",
    "\n",
    "\n",
    "eval_metric = 'auc'  #使用AUC衡量指标\n",
    "evaluator = Evaluator(eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e27f47",
   "metadata": {},
   "source": [
    "### 2.5 训练\n",
    "\n",
    "使用训练集中的节点用于训练模型，并使用验证集进行挑选模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f623ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "##train\n",
    "def train(model, data, train_idx, optimizer):\n",
    "     # data.y is labels of shape (N, )\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x,data.adj_t)[train_idx]\n",
    "\n",
    "    loss = F.nll_loss(out, data.y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56795f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "##test，评估模型在训练集和测试集上的表现\n",
    "def test(model, data, split_idx, evaluator):\n",
    "\n",
    "    with torch.no_grad():     #在 with 块中禁用梯度计算，以减少内存使用并加快计算速度，因为在评估模型时不需要反向传播。\n",
    "        model.eval()          #把模型切换到eval模式（禁用dropout等只在训练时使用的layer）\n",
    "        out = model(data.x, data.adj_t)     #使用data.x和data.adj_t进行forward传输，得到输出结果\n",
    "        y_pred = out.exp()                  #对输出进行指数操作，得到预测值y_pred\n",
    "        losses, eval_results = dict(), dict()    ##初始化losses,eval_results\n",
    "        ##增加测试集test\n",
    "        for key in ['train', 'valid']:\n",
    "            node_id = split_idx[key]\n",
    "            # out = model(data.x[node_id],data.edge_index)\n",
    "            # y_pred = out.exp()  # (N,num_classes)\n",
    "            #计算losses和eval_results\n",
    "            losses[key] = F.nll_loss(out[node_id], data.y[node_id]).item()\n",
    "            eval_results[key] = evaluator.eval(data.y[node_id], y_pred[node_id])[eval_metric]\n",
    "\n",
    "            # if len(torch.unique(data.y[node_id])) > 1:\n",
    "            #     eval_results[key] = evaluator.eval(data.y[node_id], y_pred[node_id])[eval_metric]\n",
    "            # else:\n",
    "            #     eval_results[key] = float('nan')  \n",
    "\n",
    "    return eval_results, losses, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fab3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2946\n",
      "Epoch: 10, Loss: 0.0926, Train: 64.675, Valid: 64.988 \n",
      "Epoch: 20, Loss: 0.0893, Train: 68.980, Valid: 68.490 \n",
      "Epoch: 30, Loss: 0.0743, Train: 70.306, Valid: 69.625 \n",
      "Epoch: 40, Loss: 0.0660, Train: 68.778, Valid: 68.510 \n",
      "Epoch: 50, Loss: 0.0657, Train: 69.563, Valid: 68.993 \n",
      "Epoch: 60, Loss: 0.0647, Train: 70.045, Valid: 69.477 \n",
      "Epoch: 70, Loss: 0.0646, Train: 70.720, Valid: 70.037 \n",
      "Epoch: 80, Loss: 0.0643, Train: 70.802, Valid: 70.092 \n",
      "Epoch: 90, Loss: 0.0643, Train: 71.007, Valid: 70.279 \n",
      "Epoch: 100, Loss: 0.0642, Train: 71.220, Valid: 70.468 \n",
      "Epoch: 110, Loss: 0.0641, Train: 71.355, Valid: 70.585 \n",
      "Epoch: 120, Loss: 0.0640, Train: 71.474, Valid: 70.689 \n",
      "Epoch: 130, Loss: 0.0640, Train: 71.584, Valid: 70.789 \n",
      "Epoch: 140, Loss: 0.0639, Train: 71.682, Valid: 70.871 \n",
      "Epoch: 150, Loss: 0.0639, Train: 71.768, Valid: 70.946 \n",
      "Epoch: 160, Loss: 0.0639, Train: 71.841, Valid: 71.014 \n",
      "Epoch: 170, Loss: 0.0638, Train: 71.906, Valid: 71.069 \n",
      "Epoch: 180, Loss: 0.0638, Train: 71.961, Valid: 71.112 \n",
      "Epoch: 190, Loss: 0.0638, Train: 72.010, Valid: 71.153 \n",
      "Epoch: 200, Loss: 0.0638, Train: 72.054, Valid: 71.187 \n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()))  #模型总参数量\n",
    "\n",
    "model.reset_parameters()#重置参数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['weight_decay'])\n",
    "best_valid = 0\n",
    "min_valid_loss = 1e8\n",
    "\n",
    "results_data_pred={}    ##创建字典，保存后续得到的测试数据\n",
    "\n",
    "for epoch in range(1,epochs + 1):\n",
    "    loss = train(model, data, train_idx, optimizer)\n",
    "    eval_results, losses, out = test(model, data, split_idx, evaluator)\n",
    "\n",
    "    train_eval, valid_eval = eval_results['train'], eval_results['valid']\n",
    "    # test_eval=eval_results['test']    #得到test的eval_results\n",
    "    train_loss, valid_loss = losses['train'], losses['valid']\n",
    "    # test_loss=losses['test']     #得到test的losses\n",
    "\n",
    "    if valid_loss < min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_dir+'/model_sage.pt') #将表现最好的模型保存\n",
    "        ##将最佳结果存入results_data_pred={}\n",
    "        results_data_pred = {\n",
    "            'train_eval': train_eval,\n",
    "            'valid_eval': valid_eval,\n",
    "            # 'test_eval': test_eval, \n",
    "            'train_loss': train_loss,\n",
    "            'valid_loss': valid_loss,\n",
    "            # 'test_loss': test_loss,\n",
    "            'y_pred': out  # 如果需要保存 y_pred\n",
    "        }\n",
    "\n",
    "\n",
    "    if epoch % log_steps == 0:\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}, '\n",
    "              f'Train: {100 * train_eval:.3f}, ' # 我们将AUC值乘上100，使其在0-100的区间内\n",
    "              f'Valid: {100 * valid_eval:.3f}')\n",
    "             # f'Test: {100 * test_eval:.3f}'#\n",
    "\n",
    "if results_data_pred:  # 确保字典非空\n",
    "    torch.save(results_data_pred, save_dir+'results_data_pred.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777a0402",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "### 2.6 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b076c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_dir+'/model_sage.pt')) #载入验证集上表现最好的模型\n",
    "##predict\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(data.x,data.adj_t)[node_id]\n",
    "        y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50a62666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9962, 0.0038])\n",
      "节点 0 预测对应的标签为:0, 为正常用户。\n",
      "tensor([0.9716, 0.0284])\n",
      "节点 3 预测对应的标签为:0, 为正常用户。\n"
     ]
    }
   ],
   "source": [
    "dic={0:\"正常用户\",1:\"欺诈用户\"}\n",
    "node_idx = 0\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n",
    "\n",
    "node_idx = 1\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537c8c0",
   "metadata": {},
   "source": [
    "## 3. 作业评分\n",
    "\n",
    "**作业要求**：    \n",
    "                         \n",
    "1. 请加载你认为训练最佳的模型（不限于图神经网络)\n",
    "2. 提交的作业包括【程序报告.pdf】和代码文件。\n",
    "\n",
    "**注意：**\n",
    "          \n",
    "1. 在训练模型等过程中如果需要**保存数据、模型**等请写到 **results** 文件夹，如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请务必将模型保存在 **results** 文件夹下。\n",
    "2. 训练出自己最好的模型后，先按照下列 cell 操作方式实现 NoteBook 加载模型测试；请测试通过在进行【系统测试】。\n",
    "3. 点击左侧栏`提交作业`后点击`生成文件`则只需勾选 `predict()` 函数的cell，即【**模型预测代码答题区域**】的 cell。\n",
    "4. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n",
    "5. 请加载你认为训练最佳的模型，即请按要求填写**模型路径**。\n",
    "6. `predict()`函数的输入和输出请不要改动。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32aad6",
   "metadata": {},
   "source": [
    "===========================================  **模型预测代码答题区域**  =========================================== \n",
    "\n",
    "在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dada9df",
   "metadata": {
    "select": true
   },
   "outputs": [],
   "source": [
    "## 生成 main.py 时请勾选此 cell\n",
    "from utils import DGraphFin\n",
    "from utils.utils import prepare_folder\n",
    "from utils.evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from typing import Union\n",
    "\n",
    "# 这里可以加载你的模型，加载模型映射到CPU\n",
    "state_dict=torch.load('./results/model_sage.pt',map_location=torch.device('cpu'))\n",
    "# 加载state_dict到模型\n",
    "model=SAGE(in_channels=20, out_channels=2,**model_para)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "\n",
    "    # 模型预测时，测试数据已经进行了归一化处理\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    load_results_data= torch.load(\"./results/results_data_pred.pt\", map_location=torch.device('cpu'))\n",
    "    out=load_results_data['y_pred']\n",
    "    out=out[node_id]\n",
    "    y_pred = out.exp()  \n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20054ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
